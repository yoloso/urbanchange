import glob
import numpy as np
import os

from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader, Subset
from torchvision import transforms

import utils


# Define data transforms
# TODO define transforms
def define_data_transforms():
    """
    Define the transforms to be applied to the data.
    :return: (dict) of transforms for each type of dataset
    """
    # ImageNet means and sds
    # https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html
    image_net_means = [0.485, 0.456, 0.406]
    image_net_sds = [0.229, 0.224, 0.225]

    # Define transforms for each split
    data_transforms = {
        'train': transforms.Compose([
            transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)
            transforms.RandomHorizontalFlip(),  # Requires (.., H, W)
            # transforms.RandomRotation(20), # Requires (.., H, W)
            transforms.Normalize(tuple(image_net_means), tuple(image_net_sds)),
        ]),
        'dev': transforms.Compose([
            transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)
            transforms.Normalize(tuple(image_net_means), tuple(image_net_sds))
        ]),
        'test': transforms.Compose([
            transforms.ToTensor(),  # Converts (H, W, C) to (C, H, W)
            transforms.Normalize(tuple(image_net_means), tuple(image_net_sds))
        ])
    }
    return data_transforms


# Urban Data class for DataLoaders
class UrbanData(Dataset):
    """
    Define the Urban Dataset.
    """

    def __init__(self, data_dir, split, transform):
        """
        Store the data filtered by the selected output variable.
        :param data_dir: (str) path to split dataset locations
        :param split: (str) one of ['train', 'valid', 'test']
        :param transform (torchvision.transforms)
        """
        # Save dataset attributes
        self.data_dir = data_dir
        self.split = split
        self.image_paths = glob.glob(
            os.path.join(data_dir, split, 'images', '*'))

        # Get transforms
        self.transform = transform

    def __len__(self):
        """
        Returns the size of the dataset
        :return: (int)
        """
        return len(self.image_paths)

    def __getitem__(self, item):
        """
        Returns a single datapoint given an index
        :param item: (int)
        :return: a tuple containing the image (res, res, 3) and annotations
        """
        # Get image and label paths
        image_path = self.image_paths[item]
        image_name = utils.get_image_name(image_path)
        annot_path = os.path.join(
            self.data_dir, self.split, 'labels', ''.join([image_name, '.txt']))

        # Load image and annotations
        X_item = Image.open(image_path)
        box_list = utils.load_annotations(annot_path)

        # Preprocess annotations # TODO
        num_objects, labels, XXXX = utils.preprocess_box_list(box_list)

        # Apply transforms # TODO
        if self.transform:
            X_item, Y_item = self.transform(X_item, Y_item)

        return X_item, Y_item

    def __del__(self):
        self.db.close()


# TODO fetch dataloader
def fetch_dataloader(dataset_types, data_dir, output_variable, params):
    """
    Fetches the DataLoader object for each type of data.
    :param dataset_types: (list) list including ['train', 'valid', 'test']
    :param data_dir: (str) directory containing data splits
    :param output_variable: (str) selected output variable
    :param params: (dict) a dictionary containing the model specifications
    :return: dataloaders (dict) a dictionary containing the DataLoader object
        for each type of data
    """

    # Build datasets for selected output variable if they do not exist
    file_path = os.path.join(data_dir, output_variable)
    if not os.path.exists(file_path):
        os.mkdir(file_path)

    if len(glob.glob(os.path.join(
            file_path, '{}*'.format(params['model_type'])))) == 0:
        # If Sat model, build dataset. If Street or Concat, alert to missing data.
        if params['model_type'] == 'sat':
            print('[INFO] Building satellite dataset...')
            build_dataset.process_sat_data(
                params['base_sat_image_file'], params['base_sat_id_file'],
                params['base_sat_labels_file'], data_dir, output_variable,
                params['sat_data_split'])
        elif params['model_type'] == 'street':
            raise Exception('[ERROR] Could not find street data.')
        elif params['model_type'] == 'concat':
            if len(glob.glob(os.path.join(
                    file_path, 'Extracted_Features', 'concat*'))) == 0:
                raise Exception('[ERROR] Could not find concatenated data.')
        else:
            raise Exception(
                '[ERROR] Model Type should be one of {sat, street, concat}')

    # Use GPU if available
    use_cuda = torch.cuda.is_available()

    # Get mean and sd dictionaries from our training set and define transforms
    transforms_dict = None
    if params['model_type'] != 'concat':
        if params['model_type'] == 'sat':
            training_band_means = utils.load_dict(
                os.path.join(data_dir, output_variable, 'band_means.json'))
            training_band_sds = utils.load_dict(
                os.path.join(data_dir, output_variable, 'band_sds.json'))
        elif params['model_type'] == 'street':
            # Means and SDs are not required as images have only 3 channels
            training_band_means, training_band_sds = None, None
        else:
            raise Exception(
                '[ERROR] Model Type should be one of {sat, street, concat}')
        transforms_dict = define_data_transforms(
            params['model_type'], training_band_means, training_band_sds)

    # Get data loaders
    dataloaders = {}

    for split in ['train', 'dev', 'test']:
        if split in dataset_types:
            # Get the correct Data class
            if params['model_type'] == 'sat':
                data = SatelliteData(
                    data_dir, output_variable, split, transforms_dict[split])
            elif params['model_type'] == 'street':
                data = StreetData(
                    data_dir, output_variable, split, transforms_dict[split])
            elif params['model_type'] == 'concat':
                data = ConcatData(data_dir, output_variable, split)
            else:
                raise Exception(
                    '[ERROR] Model Type should be one of {sat, street, concat}')

            # Filter for subset of the data
            np.random.seed(42)
            subset_percent = params['subset_percent']
            data_size = int(subset_percent * len(data))
            filter_indices = np.random.randint(0, high=len(data), size=data_size)
            data = Subset(data, filter_indices)

            # Grab dataloader for the data class and split
            dl = DataLoader(
                dataset=data, batch_size=params['batch_size'], shuffle=True,
                num_workers=params['num_workers'], pin_memory=use_cuda)
            dataloaders[split] = dl

    return dataloaders